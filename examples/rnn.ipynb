{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from vanilla_neural_nets.recurrent_neural_network.network import VanillaRecurrentNeuralNetwork\n",
    "from vanilla_neural_nets.recurrent_neural_network.optimization_algorithm import RNNGradientDescent\n",
    "from vanilla_neural_nets.recurrent_neural_network.backpropagate_through_time import RNNBackPropagateThroughTime\n",
    "from vanilla_neural_nets.recurrent_neural_network.parameter_initialization import OneOverRootNWeightInitializer\n",
    "from vanilla_neural_nets.recurrent_neural_network.training_data import WordLevelRNNTrainingDataBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load old blog posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCABULARY_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CORPUS = \"\"\"\n",
    "I spent seven-plus weeks this summer in the Balkans and Eastern Europe. For a week-plus, I necessarily reconnected with an old love interest to tighten loose ends. For another, I discovered Kosovo, falling hard for the youth, optimism and bullishness of its decidedly ugly capital Pristina, and watching films alongside castles, technologists, dashing Danish women and qebapa at Prizen’s DokuFest. In a third week, I went hiking in the Albanian Alps as originally planned. In a fourth, I rebuilt this website and constructed syllabi for two data science courses I was to later teach. For the remaining ~3 weeks, I wondered: what the fuck am I really doing here?\n",
    "\n",
    "My two-plus-year trip around the world was perhaps the most meaningful experience of my life. Still, almost three years after finish, I have not fully processed what it truly meant to me. I was on fire, back then. I felt concrete purpose in my steps. I carried unwavering bewilderment in my eyes and an unbeatable smile on my face. The people I met were characters in a beautiful, awesome story. Arriving in a new city, backpack aback and a half-charged iPod in my front pocket was a moment of romance. Parting ways with new friends with a “have fun out there” was my full-hearted salute to a fellow soldier on the battlefield of travel. There was nothing else I wanted to do with my time.\n",
    "\n",
    "Upon return, I picked up a new hobby: data science. I moved to New York City where my hobby was my job. I started speaking differently – discussing technologies, companies and investment – using words I previously found alien, and ugly. Relationships became interesting: all the depth, beauty and rhythm I once found in constant change was right there in my peers. In my boss, Alex. In my neighbor, Olga. None of these things are bad. Simply, I grew as a person into someone new.\n",
    "\n",
    "Until this summer, traveling to new places seemed like panacea. More than anything, this was supported by my own personal experiences on the road – by the immense joy and creative energy it had always brought. This summer, getting lost in new places and eating new foods was not the experience it always was. My relationship with travel has started to change.\n",
    "\n",
    "Travel was enthralling because it was a challenge. The theme of my trip ’round the world was thus: to relentlessly flog myself mentally, physically and emotionally, and see what came out the other end. And I did it. I became fluent in a new language. I traveled by land from Sweden to Côte d’Ivoire. I pedaled 10,000 kilometers on a bicycle. I fell in love. I learned how to really solve problems. And when it was over, landing in Philadelphia International, I cried, cried and cried. I hadn’t the slightest regret in the world. I did, almost meticulously, exactly what I set out to do.\n",
    "\n",
    "This summer brought one challenge: revisiting a previous love. That week, in all frankness, was exhilarating. That week – while we did nothing more than camp, eat, laugh and walk – was one of the sickest adventures in recent years. But that week aside – that challenge aside – there was nothing more than unknown cities I knew how to navigate; unknown, 48-hour strangers I knew how to befriend; unknown languages I felt I could speak. I was not in awe. This summer was one of hiking, delicious produce, an education in Balkan history and my tent, all baked into a lukewarm soup. It was not like my trip before; it was not that which I know travel can bring.\n",
    "\n",
    "Moving forward, I’m conscious of the following: it’s not about travel; it’s about doing things that scare you. It’s about “breaking off” something big – “I’m going to cycle from Cairo to Cape Town;” “I’m going to learn the viola in the next 60 days;” “I’m going to teach myself product management and get hired as a Product Manager” – and knocking it down. Then, once more, every second does become exhilarating in proportion to your goal. The people you meet do become pointed characters in your story. Life becomes a circuitous and enriching journey to a tenable end.\n",
    "\n",
    "Travel is an evolutionary process. At the start, the novelty of diverse company, foreign currency and what’s for breakfast suffices to keep our cheeks pinned wide and our spirit on edge. Thereafter, this decays: the uncomfortable becomes comfortable with time and experience, and we must fight harder and harder to get the same high.\n",
    "\n",
    "So, what’s the solution? Where do we go from here?\n",
    "\n",
    "First and foremost, we must realize that we, humans, are always growing, and fundamentally, our path to happiness is growing in suit. This is a path marked not by the things we do, but the context in which we do them. Our first trip, kiss and job are memorable not because of the concrete action, necessarily, but more so because of the novelty of the experience and the emotional reward that brings.\n",
    "\n",
    "Next, it follows that our once-stalwart road to ecstasy might not be our next. Sadly, I will never be able to “do” my trip again; a two-year trip around the world is not my next high. This took considerable time, effort and humility to realize.\n",
    "\n",
    "Lastly, the potential for explosive inspiration and liquid-like passion for life itself is always there. To find it, we must be honest with ourselves: honest about what we truly want, honest about what scares us, honest about our tolerance for risk. Then, we take these answers and throw ourselves into something foreign, something enriching, something that demands we find something in and of ourselves that we haven’t found before.\n",
    "\n",
    "Moving forward, I’d like to travel and work. Increasingly (and really, I started at 0…) I see work as beautiful thing, and fortunately, my hobby is my job. I recently finished two weeks of work in Bogotá – creating data science courses for Platzi – the first time I’d really combined my passion for travel with the professional world. All of a sudden, arriving to a hotel, meeting new people, going for runs and taking photos became enthralling – rimmed with playful novelty by virtue of being somewhere new – and brimming with adrenaline, as I wanted to do a great job. Those two weeks were memorable because I faced a new challenge. And for what it’s worth, if someone said “here’s two weeks in Bogotá – the capital of your favorite country in the world – now go, just, walk around,” I likely would have said no (preferring to study data science things in my bedroom, or something).\n",
    "\n",
    "I currently write from my new apartment in Casablanca, Morocco. Here, I’m pursuing a self-directed “Masters” in machine learning and speaking some French. (Incidentally, few people understand what I’m doing, why I’m doing it and how I’ll ever be hired again, which only adds to the challenge.)\n",
    "\n",
    "I can’t wait to not move. I can’t wait to memorize the smells of my street and find the best baked goods within a 3-block radius. I can’t wait to learn more about the people in my co-working space. In fact, I can’t wait for tomorrow.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data = WordLevelRNNTrainingDataBuilder.build(\n",
    "    corpus=CORPUS,\n",
    "    vocabulary_size=VOCABULARY_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize network hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HIDDEN_LAYER_SIZE = 50\n",
    "BACKPROP_THROUGH_TIME_STEPS = 4\n",
    "LEARNING_RATE = 0.05\n",
    "N_EPOCHS = 20\n",
    "RANDOM_STATE = 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnn = VanillaRecurrentNeuralNetwork(\n",
    "            vocabulary_size=VOCABULARY_SIZE,\n",
    "            hidden_layer_size=HIDDEN_LAYER_SIZE,\n",
    "            backprop_through_time_steps=BACKPROP_THROUGH_TIME_STEPS,\n",
    "            backprop_through_time_class=RNNBackPropagateThroughTime,\n",
    "            optimization_algorithm_class=RNNGradientDescent,\n",
    "            weight_initializer_class=OneOverRootNWeightInitializer,\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            n_epochs=N_EPOCHS,\n",
    "            random_state=RANDOM_STATE,\n",
    "            log_training_loss=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 62.91776\n",
      "Epoch: 1 | Loss: 61.27058\n",
      "Epoch: 2 | Loss: 41.65133\n",
      "Epoch: 3 | Loss: 34.74327\n",
      "Epoch: 4 | Loss: 27.84128\n",
      "Epoch: 5 | Loss: 38.50796\n",
      "Epoch: 6 | Loss: 33.20304\n",
      "Epoch: 7 | Loss: 42.28979\n",
      "Epoch: 8 | Loss: 33.2219\n",
      "Epoch: 9 | Loss: 34.65328\n",
      "Epoch: 10 | Loss: 31.92525\n",
      "Epoch: 11 | Loss: 30.17499\n",
      "Epoch: 12 | Loss: 35.24904\n",
      "Epoch: 13 | Loss: 34.78486\n",
      "Epoch: 14 | Loss: 33.3544\n",
      "Epoch: 15 | Loss: 27.31326\n",
      "Epoch: 16 | Loss: 29.2703\n",
      "Epoch: 17 | Loss: 30.26249\n",
      "Epoch: 18 | Loss: 29.25408\n",
      "Epoch: 19 | Loss: 27.89172\n"
     ]
    }
   ],
   "source": [
    "rnn.fit(training_data.X_train, training_data.y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_new_sentence(network):\n",
    "    sentence = [sentence_start_index]\n",
    "    while not sentence[-1] == sentence_end_index:\n",
    "        next_word_index_predictions = network.predict(sentence)\n",
    "        next_word_index = np.argmax( np.random.multinomial(1, next_word_index_predictions[-1]) )\n",
    "        \n",
    "        if next_word_index in training_data.index_to_token_lookup.keys():\n",
    "            sentence.append(next_word_index)\n",
    "    \n",
    "    return [training_data.index_to_token_lookup[index] for index in sentence[1:-1]]\n",
    "\n",
    "\n",
    "def conditional_sentence_join(corpus):\n",
    "    corpus = [('' if char in string.punctuation else ' ') + char for char in corpus]\n",
    "    return ''.join(corpus).strip()\n",
    "\n",
    "def generate_new_corpus(network):\n",
    "    new_corpus = []\n",
    "\n",
    "    for _ in range(NUMBER_OF_SENTENCES):\n",
    "        sentence = []\n",
    "        while len(sentence) < MIN_SENTENCE_LENGTH or len(sentence) > MAX_SENTENCE_LENGTH:\n",
    "            sentence = generate_new_sentence(network)\n",
    "        new_corpus += sentence\n",
    "    return new_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_SENTENCES = 10\n",
    "MIN_SENTENCE_LENGTH = 10\n",
    "MAX_SENTENCE_LENGTH = 25\n",
    "\n",
    "sentence_start_index = training_data.token_to_index_lookup['SENTENCE_START']\n",
    "sentence_end_index = training_data.token_to_index_lookup['SENTENCE_END']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "but haven’t what’s follows capital in which tomorrow adds. to for, to do than morocco experience – street the awesome would, philadelphia took weeks i can’t best journey i’m for. our can’t, i international bedroom, on process balkan but reward conscious. i can’t wait slightest processed knew on someone something,. aside. cairo recently wait pursuing at bedroom which someone came. really can’t, weeks back. taking somewhere in really being right casablanca understand and the. i fact the at more concrete which goods worth preferring again find a of peers weeks machine preferring write brimming within. i can’t wait foreign – novelty know of ugly my personal i novelty. the was, love the fundamentally investment time growing.\n"
     ]
    }
   ],
   "source": [
    "new_corpus = generate_new_corpus(rnn)\n",
    "    \n",
    "print( conditional_sentence_join(new_corpus) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vanilla_neural_nets.recurrent_neural_network.network import VanillaLSTM\n",
    "from vanilla_neural_nets.recurrent_neural_network.optimization_algorithm import LSTMGradientDescent\n",
    "from vanilla_neural_nets.recurrent_neural_network.backpropagate_through_time import LSTMBackpropagateThroughTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm = VanillaLSTM(\n",
    "    vocabulary_size=VOCABULARY_SIZE,\n",
    "    hidden_layer_size=HIDDEN_LAYER_SIZE,\n",
    "    backprop_through_time_steps=BACKPROP_THROUGH_TIME_STEPS,\n",
    "    backprop_through_time_class=LSTMBackpropagateThroughTime,\n",
    "    optimization_algorithm_class=LSTMGradientDescent,\n",
    "    weight_initializer_class=OneOverRootNWeightInitializer,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    random_state=RANDOM_STATE,\n",
    "    log_training_loss=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 24 11:53:51 WEST 2016\r\n"
     ]
    }
   ],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 53.01428\n",
      "Epoch: 1 | Loss: 48.81619\n",
      "Epoch: 2 | Loss: 47.49772\n",
      "Epoch: 3 | Loss: 45.51955\n",
      "Epoch: 4 | Loss: 43.87413\n",
      "Epoch: 5 | Loss: 43.0154\n",
      "Epoch: 6 | Loss: 42.20726\n",
      "Epoch: 7 | Loss: 41.25831\n",
      "Epoch: 8 | Loss: 40.30108\n",
      "Epoch: 9 | Loss: 39.91726\n",
      "Epoch: 10 | Loss: 39.36822\n",
      "Epoch: 11 | Loss: 37.28686\n",
      "Epoch: 12 | Loss: 36.46894\n",
      "Epoch: 13 | Loss: 34.9984\n",
      "Epoch: 14 | Loss: 34.10033\n",
      "Epoch: 15 | Loss: 32.58338\n",
      "Epoch: 16 | Loss: 32.56499\n",
      "Epoch: 17 | Loss: 31.85939\n",
      "Epoch: 18 | Loss: 29.95579\n",
      "Epoch: 19 | Loss: 28.54339\n"
     ]
    }
   ],
   "source": [
    "lstm.fit(training_data.X_train, training_data.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "travel, love time wait my people proportion has. it, my we write fortunately in the it. i’m summer for the creative morocco, my of full-hearted of people. i and all, hired was from next a revisiting – life – are write. that forward what weeks wait wait keep with how within two. manager” process became to started learn always to work in the steps neighbor found or prizen’s change the beautiful professional professional my the becomes. parting of next bedroom decidedly revisiting wait energy with great in my job. enthralling moving going i move i the steps tomorrow in people to the the next. i can’t that wait self-directed eyes travel started the wanted, became in about it as processed, my). an, humility can’t a wait foreign foreign in new and to walk before week doing.\n"
     ]
    }
   ],
   "source": [
    "new_corpus = generate_new_corpus(lstm)\n",
    "    \n",
    "print( conditional_sentence_join(new_corpus) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
